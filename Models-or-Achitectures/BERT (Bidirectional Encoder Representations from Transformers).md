# Intro
## Brief
1. [[Transformer]]
2. BERT: http://jalammar.github.io/illustrated-bert/

## Detailed (Research papers)
### General
1. Transformer Models: [[Attention Is All You Need]] 
2. [[BERT Pre-training of Deep Bidirectional Transformers for Language Understanding]]

### Specific to medical domain
1. [[ClinicalBERT- Modeling Clinical Notes and Predicting Hospital Readmission]]
2. [[Publically Available Clinical BERT Embeddings]]

## Hands-on
#### NOTE: we will be using [[Huggingface]] library for application of BERT/transformer models.